{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3136,"databundleVersionId":26502,"sourceType":"competition"}],"dockerImageVersionId":31089,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-07-13T14:38:09.760449Z","iopub.execute_input":"2025-07-13T14:38:09.760731Z","iopub.status.idle":"2025-07-13T14:38:11.747369Z","shell.execute_reply.started":"2025-07-13T14:38:09.760704Z","shell.execute_reply":"2025-07-13T14:38:11.746299Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/titanic/train.csv\n/kaggle/input/titanic/test.csv\n/kaggle/input/titanic/gender_submission.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"train=pd.read_csv('/kaggle/input/titanic/train.csv')\nprint(train.head())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T14:42:10.965199Z","iopub.execute_input":"2025-07-13T14:42:10.965957Z","iopub.status.idle":"2025-07-13T14:42:10.986442Z","shell.execute_reply.started":"2025-07-13T14:42:10.965927Z","shell.execute_reply":"2025-07-13T14:42:10.985563Z"}},"outputs":[{"name":"stdout","text":"   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n3            4         1       1   \n4            5         0       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n4                           Allen, Mr. William Henry    male  35.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  \n3      0            113803  53.1000  C123        S  \n4      0            373450   8.0500   NaN        S  \n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"train.describe(include=\"all\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T12:30:02.852995Z","iopub.execute_input":"2025-07-13T12:30:02.853459Z","iopub.status.idle":"2025-07-13T12:30:02.918304Z","shell.execute_reply.started":"2025-07-13T12:30:02.853432Z","shell.execute_reply":"2025-07-13T12:30:02.917399Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import joblib","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T14:42:13.602779Z","iopub.execute_input":"2025-07-13T14:42:13.603089Z","iopub.status.idle":"2025-07-13T14:42:13.635752Z","shell.execute_reply.started":"2025-07-13T14:42:13.603066Z","shell.execute_reply":"2025-07-13T14:42:13.635098Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def clean_transform_df(df):\n    df=df.copy()\n    df=df.set_index('PassengerId')\n\n    #Extract titles\n    df['Title']=df['Name'].str.extract(r'([A-Za-z]+)\\.', expand=False)\n\n    title_mapping={'Mlle':'Miss','Ms':'Miss','Mme':'Mrs'}\n    df['Title']=df['Title'].replace(title_mapping)\n\n    rare_titles=df['Title'].value_counts()[df['Title'].value_counts()<10].index\n    df['Title'] = df['Title'].replace(rare_titles, 'Rare')\n    \n    title_mask=~df['Title'].isin(['Mr', 'Miss', 'Mrs', 'Master', 'Rare'])\n    df.loc[title_mask, 'Title']= df.loc[title_mask, 'Sex'].map({'male': 'Mr', 'female': 'Mrs'})\n\n    title_age_medians={\n        'Mr': 32.32,\n        'Miss': 21.68,\n        'Mrs': 35.86,\n        'Master': 4.57,\n        'Rare': 48.5\n    }\n\n    for title, median_age in title_age_medians.items():\n        age_mask=(df['Age'].isnull())&(df['Title']==title)\n        df.loc[age_mask, 'Age']=median_age\n\n    #Replace inpace fillna operations\n    df['Embarked']=df['Embarked'].fillna(df['Embarked'].mode()[0])\n    df['Fare']=df['Fare'].fillna(df['Fare'].median())\n\n    df['Age*Class']=df['Age']*df['Pclass']\n    df['Age*Fare']=df['Age']*df['Fare']\n\n    df_sex=pd.get_dummies(df['Sex'], prefix='sex', drop_first=True, dtype=int)\n    df_Pclass=pd.get_dummies(df['Pclass'], prefix='class', drop_first=True, dtype=int)\n    df_Embarked=pd.get_dummies(df['Embarked'], prefix='Embarked', drop_first=True, dtype=int)\n    df_Title=pd.get_dummies(df['Title'], prefix='Title', drop_first=False, dtype=int)\n\n    df=pd.concat([df, df_sex, df_Pclass, df_Embarked, df_Title], axis=1)\n\n    #Family features\n    df['FamilySize']=df['SibSp']+df['Parch']+1\n    df['IsAlone']=(df['FamilySize']==1).astype(int)\n    df['Fare_Per_Person'] = df['Fare'] / df['FamilySize']\n\n    # Fare and Age bands\n    df['AgeBand'] = pd.cut(df['Age'], bins=[0, 12, 20, 40, 60, np.inf], labels=[0, 1, 2, 3, 4])\n    df['AgeBand'] = df['AgeBand'].astype(int)\n\n    df['FareBand']=pd.qcut(df['Fare'], q=4, labels=[0,1,2,3])\n    df['FareBand']=df['FareBand'].astype(int)\n\n    #Log transformation\n    df['Fare_log']=np.log1p(df['Fare'])\n\n    df['Cabin'] = df['Cabin'].fillna('U0')\n    df['Deck'] = df['Cabin'].str[0]\n    df = pd.get_dummies(df, columns=['Deck'], drop_first=True)\n\n    df=df.drop(['Sex', 'Pclass', 'Name', 'Ticket', 'Embarked', 'Cabin', 'Title', 'Fare', 'SibSp', 'Parch'], axis=1)\n\n    #Scaling only scale numeric columns\n    numeric_columns=df.select_dtypes(include=['float64', 'int64']).columns\n\n    mew=df[numeric_columns].mean(axis=0)\n    std=df[numeric_columns].std(axis=0)\n    df[numeric_columns]=(df[numeric_columns]-mew)/std\n\n    return df","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T14:50:36.749058Z","iopub.execute_input":"2025-07-13T14:50:36.749334Z","iopub.status.idle":"2025-07-13T14:50:36.763834Z","shell.execute_reply.started":"2025-07-13T14:50:36.749313Z","shell.execute_reply":"2025-07-13T14:50:36.762878Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"'''\n#Load model\nmodel=joblib.load(\"/kaggle/input/titanic-random-forest-0.794-score/scikitlearn/default/2/titanic_model.pkl\")\n'''\nimport lightgbm as lgb\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\n\ny_train=train['Survived']\nX_train=clean_transform_df(train.drop(columns=['Survived']))\n\nmodel = lgb.LGBMClassifier(random_state=42, n_estimators=100)\nmodel.fit(X_train, y_train)\n\n#Load and preprocess test data\ntest_data=pd.read_csv('/kaggle/input/titanic/test.csv')\ntest_features=clean_transform_df(test_data)\n\ntrain_columns = X_train.columns\nfor col in train_columns:\n    if col not in test_features.columns:\n        test_features[col] = 0\n\n#Make predictions\npredictions=model.predict(test_features)\n\n#Create submission file\nsubmission=pd.DataFrame({\n    'PassengerID': test_features.index,\n    'Survived': predictions\n})\n\nsubmission.to_csv('submission.csv', index=False)\n\ntrain_preds=model.predict(X_train)\nprint('Training accuracy:', accuracy_score(y_train, train_preds))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-07-13T14:50:39.164253Z","iopub.execute_input":"2025-07-13T14:50:39.164554Z","iopub.status.idle":"2025-07-13T14:50:39.424243Z","shell.execute_reply.started":"2025-07-13T14:50:39.164529Z","shell.execute_reply":"2025-07-13T14:50:39.423326Z"}},"outputs":[{"name":"stdout","text":"[LightGBM] [Info] Number of positive: 342, number of negative: 549\n[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002845 seconds.\nYou can set `force_row_wise=true` to remove the overhead.\nAnd if memory is not enough, you can set `force_col_wise=true`.\n[LightGBM] [Info] Total Bins 765\n[LightGBM] [Info] Number of data points in the train set: 891, number of used features: 24\n[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.383838 -> initscore=-0.473288\n[LightGBM] [Info] Start training from score -0.473288\nTraining accuracy: 0.9809203142536476\n","output_type":"stream"}],"execution_count":8}]}